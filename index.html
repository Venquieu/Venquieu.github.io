<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.1.1"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Config-GitHub-Pages-with-Hexo" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/30/Config-GitHub-Pages-with-Hexo/" class="article-date">
  <time class="dt-published" datetime="2024-03-30T10:44:21.000Z" itemprop="datePublished">2024-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/30/Config-GitHub-Pages-with-Hexo/">使用Hexo搭建GitHub博客</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>之前使用WordPress部署个人博客，但是因为自己买主机太贵不合算，所以迁到GitHub上。开始时候使用<code>Jekyll</code>部署，可惜<code>Jekyll</code>主题普遍不够美观，所以又改用<code>Hexo</code>部署，这里记录一下<code>Hexo</code>部署的过程吧。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>需要安装 <code>Node.js</code>和<code>Git</code>，安装 <code>Node.js</code>之后可以用其<code>npm</code>工具安装<code>Hexo</code>。</p>
<ol>
<li><p>安装<a target="_blank" rel="noopener" href="https://git-scm.com/downloads">Git</a>。<br>安装完成后可以通过<code>Git Bash</code>进入Terminal，在Terminal输入<code>git --version</code>查看版本信息；(也可以通过Windows的cmd命令行查看，不过我觉得Terminal更好，因为其和Linux使用体验完全一致)</p>
</li>
<li><p>安装<a target="_blank" rel="noopener" href="https://nodejs.org/en">Node.js</a>。<br>安装完成后可以在Terminal输入<code>node -v</code>和<code>npm -v</code>查看版本信息；</p>
</li>
<li><p>安装<code>Hexo</code>。<br>创建<code>Hexo</code>的安装路径，比如<code>D:\softwares\Hexo</code>，在安装路径下打开Terminal进行安装：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br><span class="line">hexo init</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>

<p>此时即可在安装路径下看到生成的文件，结构附在后边。<br>注意：后续<strong>涉及到<code>Hexo</code>的命令行操作都需要在安装路径下的终端（Terminal或者cmd）执行</strong>。</p>
</li>
</ol>
<h2 id="配置Git"><a href="#配置Git" class="headerlink" title="配置Git"></a>配置Git</h2><p>首先确保自己有GitHub账户。</p>
<ol>
<li><p>创建用于博客的仓库。<br>仓库名字必须是<code>username.github.io</code>，相关步骤不赘述。</p>
</li>
<li><p>本地配置Git账户并设置免密。<br>Terminal输入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;your username&quot;</span><br><span class="line">git config --global user.email &quot;your email&quot;</span><br><span class="line"></span><br><span class="line"># HTTP免密，SSH免密也可以，个人比较喜欢HTTP免密，步骤更简单</span><br><span class="line">git config --global credential.helper store</span><br></pre></td></tr></table></figure>

<p>因为<code>Hexo</code>部署时候会自动更新仓库内容，所以必须设置免密。</p>
</li>
<li><p>（Optional）可以测试一下自己上边的设置有没有问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/[username]/[username].github.io.git</span><br></pre></td></tr></table></figure>

<p>如果成功拉下来就表明配置没有问题。</p>
</li>
</ol>
<h2 id="Hexo部署至GitHub-Pages"><a href="#Hexo部署至GitHub-Pages" class="headerlink" title="Hexo部署至GitHub Pages"></a>Hexo部署至GitHub Pages</h2><ol>
<li><p>（Optional）测试本地安装的<code>Hexo</code>是否正常。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p>如果一切正常，此时访问<code>http://localhost:4000</code>就会看到<code>Hexo</code>的默认页面。</p>
</li>
<li><p>安装<code>hexo-deployer-git</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>
</li>
<li><p>修改<code>Hexo</code>安装路径下的<code> _config.yml</code>文件末尾的<code>deploy</code>部分为如下形式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git</span><br><span class="line">  repository: https://github.com/[username]/[username].github.io.git</span><br><span class="line">  branch: main</span><br></pre></td></tr></table></figure>

<p>注意两点，一是<code>repository</code>与上边免密方式对应，我这里是HTTP免密，如果是SSH免密，形式为<code>git@github.com:[username]/[username].github.io.git</code>；二是<code>branch</code>应该与GitHub Pages使用的分支一致，通常为<code>main</code>或者<code>master</code>。</p>
</li>
<li><p>上传部署。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<p>此时访问<code>https://[username].github.io</code>即可看到部署完成的网站了，同时也可以看到自己的仓库也对应更新了。</p>
</li>
</ol>
<h2 id="补充信息"><a href="#补充信息" class="headerlink" title="补充信息"></a>补充信息</h2><h3 id="Hexo安装路径下的文件信息"><a href="#Hexo安装路径下的文件信息" class="headerlink" title="Hexo安装路径下的文件信息"></a>Hexo安装路径下的文件信息</h3><p>这里仅列出部分比较重要的文件夹&#x2F;文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Hexo_dir</span><br><span class="line">├── public			# 将被更新到博客仓库的内容</span><br><span class="line">├── scaffolds		# 模版文件</span><br><span class="line">├── source			# 存放markdown格式的博客</span><br><span class="line">├── themes			# 存放Hexo主题</span><br><span class="line">├── _config.yml		# 网站的配置信息</span><br><span class="line">└── package.json	# 应用程序的信息</span><br></pre></td></tr></table></figure>

<h3 id="修改主题"><a href="#修改主题" class="headerlink" title="修改主题"></a>修改主题</h3><ol>
<li>将自己想要的主题拷贝至<code>themes</code>文件夹下；</li>
<li>修改<code>_config.yml</code>中的<code>theme</code>为新主题名字；</li>
<li>发布和部署。</li>
</ol>
<h3 id="常用Hexo命令"><a href="#常用Hexo命令" class="headerlink" title="常用Hexo命令"></a>常用Hexo命令</h3><p>Refer to：<a target="_blank" rel="noopener" href="https://hexo.io/docs/">Documentation | Hexo</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建文章，在source\_posts会生成同名markdown文档，打开并编辑即可</span></span><br><span class="line">hexo new <span class="string">&quot;post name&quot;</span></span><br><span class="line"><span class="comment"># 生成博客页面</span></span><br><span class="line">hexo g</span><br><span class="line"><span class="comment"># 启动本地预览</span></span><br><span class="line">hexo s</span><br><span class="line"><span class="comment"># 部署和发布至GitHub Pages</span></span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>



<h2 id="WordPress博客迁移至Hexo"><a href="#WordPress博客迁移至Hexo" class="headerlink" title="WordPress博客迁移至Hexo"></a>WordPress博客迁移至Hexo</h2><p>Refer to：<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/migration.html#WordPress">迁移 | Hexo</a></p>
<p>使用体验一般，主要存在的问题一是公式解析出问题；二是媒体文件需要重定向路径；三是表格、段落可能出错。如果WordPress里边的内容非常多，迁移工作将非常耗时。不过还能要啥自行车呢？</p>
<h3 id="导出WordPress内容"><a href="#导出WordPress内容" class="headerlink" title="导出WordPress内容"></a>导出WordPress内容</h3><p>WordPress需要导出的内容大致分两类，一类是文章，另一类是媒体。</p>
<ol>
<li>文章导出。进入WordPress后台，<code>工具-&gt;导出</code>，导出需要的内容，将会以<code>xml</code>文件格式下载下来。</li>
<li>媒体导出。媒体文件存在于WordPress网站目录下的<code>uploads</code>文件夹中，将其下载到本地即可；如果是本地部署的话则位于WordPress目录下的<code>wp-content\uploads</code>中。</li>
</ol>
<h3 id="导入Hexo"><a href="#导入Hexo" class="headerlink" title="导入Hexo"></a>导入Hexo</h3><ol>
<li><p>文章导入。将上边下载下来的<code>xml</code>文件导入进来。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-migrator-wordpress --save</span><br><span class="line">hexo migrate wordpress &lt;wordpress.xml&gt;</span><br></pre></td></tr></table></figure>

<p>此时即可在<code>source\_posts</code>下看到导入的文章了，如果有草稿则存在于<code>source\_drafts</code>下。</p>
</li>
<li><p>将媒体文件放在合适的地方。比如我倾向于放在<code>source\assets</code>下。</p>
</li>
<li><p>逐篇校对导入的文章，将媒体重定向为新的路径，同时注意公式等有没有解析出错。</p>
</li>
<li><p>部署上传。</p>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/30/Config-GitHub-Pages-with-Hexo/" data-id="clue6skky00001w159olkgpu2" data-title="使用Hexo搭建GitHub博客" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-hello-world" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2024/03/30/hello-world/" class="article-date">
  <time class="dt-published" datetime="2024-03-30T04:37:02.522Z" itemprop="datePublished">2024-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2024/03/30/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2024/03/30/hello-world/" data-id="cludlt82c0000ww15dcqe0ocg" data-title="Hello World" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-pytorch-model-to-onnx" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/03/05/pytorch-model-to-onnx/" class="article-date">
  <time class="dt-published" datetime="2023-03-05T08:53:53.000Z" itemprop="datePublished">2023-03-05</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/">深度学习模型部署</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/03/05/pytorch-model-to-onnx/">pyTorch模型转onnx</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>pyTorch模型转换为onnx格式相对来说是比较简单的，因为pyTorch提供了<code>torch.onnx</code>模块用于实现这一转换过程。</p>
<h2 id="基本实现"><a href="#基本实现" class="headerlink" title="基本实现"></a>基本实现</h2><p>将pyTorch模型转换为onnx格式的基本流程和<a target="_blank" rel="noopener" href="http://localhost/wordpress/deployment/pytorch_model_to_torchscript/" title="转换为TorchScript格式">转换为TorchScript格式</a>是一样的，这是因为无论转换为TorchScript还是onnx都需要对<code>torch.nn.Module</code>进行tracing操作以记录模型所有的运算。</p>
<h3 id="torch-onnx-export-函数说明"><a href="#torch-onnx-export-函数说明" class="headerlink" title="torch.onnx.export 函数说明"></a>torch.onnx.export 函数说明</h3><p>两者的不同之处在于实现转换功能的函数，转换为onnx格式需要用函数<code>torch.onnx.export</code>[2]实现。函数的用法pyTorch官方有详细的介绍，不过我觉得还是有必要将重点用更简单的语言说一下。函数格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">torch.onnx.export(model, args, f, export_params=True, verbose=False, training=&lt;TrainingMode.EVAL: 0&gt;, \</span><br><span class="line">                  input_names=None, output_names=None, operator_export_type=&lt;OperatorExportTypes.ONNX: 0&gt;, \</span><br><span class="line">                  opset_version=None, do_constant_folding=True, dynamic_axes=None, keep_initializers_as_inputs=None, </span><br><span class="line">                  custom_opsets=None, export_modules_as_functions=False)</span><br></pre></td></tr></table></figure>

<p>看起来一堆参数，但是实际上必须的参数只有三个：</p>
<ul>
<li><p><strong><code>model</code></strong>: 要进行转换的模型，通常是加载好权重的<code>torch.nn.Module</code>实例。 多说一句，<code>model</code>也可以是<code>torch.jit.ScriptModule</code>，实际上<code>torch.onnx.export</code>转换时处理的就是<code>torch.jit.ScriptModule</code>实例，如果输入是<code>torch.nn.Module</code>实例，那么就会首先被转换为<code>torch.jit.ScriptModule</code>。</p>
</li>
<li><p><strong><code>args</code></strong>: 模型<code>model</code>的输入参数，可以是元组或者<code>torch.Tensor</code>。</p>
</li>
<li><p><strong><code>f</code></strong>: 简单理解是导出文件的名字，此时需要是一个包含文件名的字符串。</p>
</li>
</ul>
<p>除了这三个必要的参数，还有一些非常重要、常用的参数：</p>
<ul>
<li><strong><code>input_names</code></strong>: 运算图输入节点的名字，类型是字符串列表</li>
<li><strong><code>output_names</code></strong> : 运算图输出节点的名字，类型是字符串列表</li>
<li><strong><code>dynamic_axes</code></strong>: 可以控制将导出的模型设置为支持输入动态维度</li>
<li><strong><code>opset_version</code></strong>: 运算集版本</li>
</ul>
<h3 id="torch-onnx-export-函数使用"><a href="#torch-onnx-export-函数使用" class="headerlink" title="torch.onnx.export 函数使用"></a>torch.onnx.export 函数使用</h3><p>下边通过一个简单的例子说明一下<code>torch.onnx.export</code>的用法。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line"># 创建模型实例，对于自定义的模型需要加载权重</span><br><span class="line">model = torchvision.models.resnet18(pretrained=True).cuda()</span><br><span class="line"></span><br><span class="line"># 评估模式</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line"># 创建一个示例输出，维度和forward函数的输入一致</span><br><span class="line">dummy_input = torch.rand(1, 3, 224, 224, device=&#x27;cuda&#x27;)</span><br><span class="line"></span><br><span class="line"># 执行转换并将结果保存为`resnet18.onnx`</span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model,</span><br><span class="line">    dummy_input,</span><br><span class="line">    &quot;resnet18.onnx&quot;,</span><br><span class="line">    input_names = [&quot;image&quot;],</span><br><span class="line">    output_names = [&quot;pred&quot;],</span><br><span class="line">    dynamic_axes = &#123;&quot;image&quot;: &#123;0: &quot;batch&quot;&#125;,</span><br><span class="line">                    &quot;label&quot;: &#123;0: &quot;batch&quot;&#125;&#125;,</span><br><span class="line">    opset_version=11</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>根据我们对于这个函数的认知，我们可以知道：这段代码最后得到了一个onnx模型，名字为<code>resnet18.onnx</code>，转换用到的操作集版本是11，<code>resnet18.onnx</code>的输入节点名字是<code>image</code>、输出节点名字是<code>pred</code>,输出和输出的batch size都是动态的，但每张输入图像的维度是固定的，那就是$ 3 \times 224 \times 224 $。</p>
<p>为了验证我们转出来的onnx模型是不是跟我们预想的一致，还可以把onnx模型上传到<a target="_blank" rel="noopener" href="https://netron.app/">https://netron.app</a> 实现可视化查看。</p>
<h2 id="完整的转换实例脚本"><a href="#完整的转换实例脚本" class="headerlink" title="完整的转换实例脚本"></a>完整的转换实例脚本</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># === import your model ===</span><br><span class="line">from model import MyModel</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(&quot;export model as onnx&quot;)</span><br><span class="line">parser.add_argument(&#x27;--checkpoint&#x27;, type=str, required=True)</span><br><span class="line">parser.add_argument(&quot;--batch-size&quot;, type=int, default=1)</span><br><span class="line">parser.add_argument(</span><br><span class="line">    &quot;--input-shape&quot;,</span><br><span class="line">    type=str,</span><br><span class="line">    default=&quot;224,224&quot;,</span><br><span class="line">    help=&quot;specify the input shape for inference&quot;)</span><br><span class="line">parser.add_argument(&quot;--dynamic&quot;, action=&quot;store_true&quot;, help=&quot;whether the input shape should be dynamic&quot;)</span><br><span class="line">parser.add_argument(&quot;--file-name&quot;, type=str, default=&quot;model.onnx&quot;, help=&quot;onnx file name&quot;)</span><br><span class="line">parser.add_argument(&quot;--input-name&quot;, type=str, default=&quot;image&quot;, help=&quot;name of input node&quot;)</span><br><span class="line">parser.add_argument(&quot;--output-name&quot;, type=str, default=&quot;pred&quot;,  help=&quot;name of output node&quot;)</span><br><span class="line">parser.add_argument(&quot;--opset&quot;, type=int, default=11, help=&quot;onnx opset version&quot;)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">model = MyModel().cuda()</span><br><span class="line">checkpoint = torch.load(args.checkpoint)</span><br><span class="line">model.load_state_dict(checkpoint)</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line">input_shape = tuple(map(int, args.input_shape.split(&quot;,&quot;)))</span><br><span class="line">dummy_input = torch.randn(args.batch_size, 6, *input_shape, device=&quot;cuda&quot;)</span><br><span class="line"></span><br><span class="line">torch.onnx.export(</span><br><span class="line">    model,</span><br><span class="line">    dummy_input,</span><br><span class="line">    args.file_name,</span><br><span class="line">    input_names = [args.input_name],</span><br><span class="line">    output_names = [args.output_name],</span><br><span class="line">    dynamic_axes = &#123;args.input_name: &#123;0: &quot;batch&quot;&#125;,</span><br><span class="line">                    args.output_name: &#123;0: &quot;batch&quot;&#125;&#125; if args.dynamic else None,</span><br><span class="line">    opset_version=args.opset,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">print(&quot;save torchscript as &quot; + args.file_name)</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1]. <a target="_blank" rel="noopener" href="https://onnxruntime.ai/docs/get-started/with-python.html">https://onnxruntime.ai/docs/get-started/with-python.html</a></p>
<p> [2]. <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/onnx.html#functions">https://pytorch.org/docs/stable/onnx.html#functions</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/03/05/pytorch-model-to-onnx/" data-id="clufcjlql000s7o15gt6e2wko" data-title="pyTorch模型转onnx" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-pytorch-model-to-torchscript" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/03/04/pytorch-model-to-torchscript/" class="article-date">
  <time class="dt-published" datetime="2023-03-04T08:15:08.000Z" itemprop="datePublished">2023-03-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/">深度学习模型部署</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/03/04/pytorch-model-to-torchscript/">pyTorch模型转torchscript</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>作为一个高效好用的深度学习框架，pyTorch被广泛用于深度学习模型的搭建和训练，但是却几乎没有人会直接将pyTorch模型用于部署。对此，pyTorch官方也给出了自己的一种解决方案——TorchScript。</p>
<p>TorchScript[1]是一种从PyTorch代码创建可序列化、可优化的模型的方法，任何TorchScript程序都可以从Python进程中保存，并加载到没有Python依赖的进程中，从而可以实现模型的部署。</p>
<p>将pyTorch模型转换成TorchScript有两种方法：一种叫tracing，另一种叫scripting。通常这两种方法任意一种都可以，但在一些特定模型结构中需要将两者结合使用。</p>
<p>鉴于tracing对于我来说已经足够，本文只关注tracing方法。</p>
<h2 id="tracing用法"><a href="#tracing用法" class="headerlink" title="tracing用法"></a>tracing用法</h2><p><code>tracing</code>方法的核心是用<code>torch.jit.trace</code>记录一次模型推理中经过的所有运算记录，将这些记录整合成计算图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torchvision</span><br><span class="line"></span><br><span class="line"># 创建模型实例，对于自定义的模型需要加载权重</span><br><span class="line">model = torchvision.models.resnet18(pretrained=True)</span><br><span class="line"></span><br><span class="line"># 评估模式</span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line"># 创建一个示例输出，维度和forward函数的输入一致</span><br><span class="line">dummy_input = torch.rand(1, 3, 224, 224)</span><br><span class="line"></span><br><span class="line"># 用 torch.jit.trace 生成 torch.jit.ScriptModule</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    traced_script_module = torch.jit.trace(model, dummy_input)</span><br><span class="line"></span><br><span class="line"># 保存 TorchScript，习惯上后缀为.pt</span><br><span class="line">traced_script_module.save(&quot;traced_resnet.pt&quot;)</span><br></pre></td></tr></table></figure>

<p>这样即可把pyTorch模型转换成TorchScript了。</p>
<h2 id="创建一个完整的转换脚本"><a href="#创建一个完整的转换脚本" class="headerlink" title="创建一个完整的转换脚本"></a>创建一个完整的转换脚本</h2><p>这里补充一个完整的转换脚本吧</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import argparse</span><br><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># === import your model ===</span><br><span class="line">from model import MyModel</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(&quot;export model as torchscript&quot;)</span><br><span class="line">parser.add_argument(&#x27;--checkpoint&#x27;, type=str, required=True)</span><br><span class="line">parser.add_argument(&quot;--batch-size&quot;, type=int, default=1)</span><br><span class="line">parser.add_argument(</span><br><span class="line">    &quot;--input-shape&quot;,</span><br><span class="line">    type=str,</span><br><span class="line">    default=&quot;224,224&quot;,</span><br><span class="line">    help=&quot;specify the input shape for inference&quot;)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line"></span><br><span class="line">model = MyModel()</span><br><span class="line">checkpoint = torch.load(args.checkpoint)</span><br><span class="line">model.load_state_dict(checkpoint)</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line"></span><br><span class="line">input_shape = tuple(map(int, args.input_shape.split(&quot;,&quot;)))</span><br><span class="line">dummy_input = torch.randn(args.batch_size, 6, *input_shape)</span><br><span class="line"></span><br><span class="line">with torch.no_grad():</span><br><span class="line">    traced_script_module = torch.jit.trace(model, dummy_input)</span><br><span class="line"></span><br><span class="line">traced_script_module.save(&quot;model.pt&quot;)</span><br><span class="line">print(&quot;save torchscript as model.pt&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="TorchScript加载"><a href="#TorchScript加载" class="headerlink" title="TorchScript加载"></a>TorchScript加载</h2><p>pyTorch模型转换成TorchScript后可以很方便地用python或者C++直接加载，如在python中可直接使用<code>torch.jit.load</code>加载序列化后的模型。</p>
<p><code>torch.jit.load</code>函数原型如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.jit.load(f, map_location=None, _extra_files=None, _restore_shapes=False)</span><br></pre></td></tr></table></figure>

<ul>
<li><code>f</code>: 一个文件流对象或者模型文件名字符串，如我们的<code>model.pt</code>;</li>
<li><code>map_location</code>: 字符串(如<code>cuda:0</code>)或<code>torch.device</code>，用于将模型映射加载到指定的设备上。 这一点很重要，因为默认情况下<code>torch.jit.load</code>会试图将模型加载到保存时所使用的设备上，如果这个设备不存在就会报错。比如保存时模型在<code>cuda:1</code>上，而我们加载时候的设备只有一张卡即<code>cuda:0</code>，那么就会出错。而通过指定<code>map_location</code>我们可以重新分配用于加载模型的设备。</li>
</ul>
<p>加载实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 使用保存时的设备加载</span><br><span class="line">model = torch.jit.load(&quot;model.pt&quot;)</span><br><span class="line"># 使用1卡加载</span><br><span class="line">model = torch.jit.load(&quot;model.pt&quot;, map_location=&quot;cuda:1&quot;)</span><br></pre></td></tr></table></figure>

<p>在C++中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auto model = torch::jit::load(&#x27;model.pt&#x27;);</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>[1]. <a target="_blank" rel="noopener" href="https://pytorch.org/docs/master/jit.html">https://pytorch.org/docs/master/jit.html</a> </p>
<p>[2]. <a target="_blank" rel="noopener" href="http://djl.ai/docs/pytorch/how_to_convert_your_model_to_torchscript.html">http://djl.ai/docs/pytorch/how_to_convert_your_model_to_torchscript.html</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/03/04/pytorch-model-to-torchscript/" data-id="clufcjlqm000w7o152kap71u4" data-title="pyTorch模型转torchscript" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-python-file-lock" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/02/19/python-file-lock/" class="article-date">
  <time class="dt-published" datetime="2023-02-19T06:00:38.000Z" itemprop="datePublished">2023-02-19</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/02/19/python-file-lock/">python实现文件锁</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <blockquote>
<p>之前写过一篇用<a target="_blank" rel="noopener" href="http://localhost/wordpress/index.php/2022/12/04/python_threads_processes">python实现多进程与多线程</a>的文章，在使用多进程或者多线程的情况下，使用锁来实现互斥以避免同时对资源执行读和写就成为一个不可避免的事情。 对于一般的变量资源来说实现互斥锁很简单，使用<code>multiprocessing.Lock</code>类或者<code>threading.Lock</code>即可。但是如果我们要实现互斥的是文件呢？</p>
</blockquote>
<p>写这篇文章的初衷是我没有找到现成的库可以用，所以特意自己写了一个想贴出来。但是写到一半的时候发现了<code>filelock</code>库可以解决这个问题，使用起来要比自己写的更好一些。索性就把原来写的全都删了，分享一下用<code>filelock</code>实现文件锁的方法。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>使用pip或者conda等安装filelock即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install filelock</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>这里将介绍一下用<code>filelock</code>模块实现文件锁的基本用法。</p>
<p> <strong>导入接口</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">from filelock import FileLock</span><br></pre></td></tr></table></figure>

<p><strong>文件和锁文件</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">file = &quot;file.txt&quot;</span><br><span class="line">lockfile = file + &quot;.lock&quot;</span><br></pre></td></tr></table></figure>

<p>这里的文件<code>file</code>是我们要实现互斥锁定的文件。 锁文件<code>lockfile</code>用于确定是否允许进程或者线程访问该文件，具体机制我们可以不必关心，能够正确创建的使用就可以了。</p>
<p> <strong>实例化锁对象</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lock = FileLock(lockfile)</span><br></pre></td></tr></table></figure>

<p>实例化出来一个锁对象<code>lock</code>，注意这里的参数是锁文件<code>lockfile</code>而不是文件<code>file</code>。 <code>lock</code>在上锁的时候，如果文件已经被其他对象上了锁，那么将一直等待到文件被其他对象释放锁后再上锁。如果不想在获取不到锁的时候永远等待下去，可以如下实例化锁对象：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lock = FileLock(lockfile, timeout = 5)</span><br></pre></td></tr></table></figure>

<p>这时，<code>lock</code>在上锁的时候，如果文件已经被其他对象上了锁，那么在5秒内如果文件被其他对象释放锁，<code>lock</code>会对其上锁；否则就会因超时而报错退出。</p>
<p> <strong>锁的获取和释放</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">lock.acquire()</span><br><span class="line"># do something...</span><br><span class="line">lock.release()</span><br></pre></td></tr></table></figure>

<p>使用方法很直观，<code>acquire()</code>方法用于获取锁，<code>release()</code>方法用于释放锁。</p>
<p><strong>完整代码</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> filelock <span class="keyword">import</span> FileLock</span><br><span class="line"></span><br><span class="line">file = <span class="string">&quot;file.txt&quot;</span></span><br><span class="line">lockfile = file + <span class="string">&quot;.lock&quot;</span></span><br><span class="line"></span><br><span class="line">lock = FileLock(lockfile)</span><br><span class="line">lock.acquire()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;acquire the lock!&quot;</span>)</span><br><span class="line">    <span class="comment"># do something to the file...</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    lock.release()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;release the lock!&quot;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>这里，我们将分别跑两个相同的脚本<code>main1.py</code>和<code>main2.py</code>以模拟多进程，这两个脚本均试图排他的获取文件<code>file.txt</code>。 <code>main1.py</code>和<code>main2.py</code>中的内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">from filelock import FileLock</span><br><span class="line"></span><br><span class="line">file = &quot;file.txt&quot;</span><br><span class="line">lockfile = &quot;file.txt.lock&quot;</span><br><span class="line"></span><br><span class="line">lock = FileLock(lockfile)</span><br><span class="line"></span><br><span class="line">lock.acquire()</span><br><span class="line">try:</span><br><span class="line">    # do something to the file...</span><br><span class="line">    time_now = time.strftime(&#x27;%H:%M:%S&#x27;, time.localtime())</span><br><span class="line">    print(time_now + &quot;: acquire the lock!&quot;)</span><br><span class="line">    time.sleep(5)</span><br><span class="line">finally:</span><br><span class="line">    lock.release()</span><br><span class="line">    time_now = time.strftime(&#x27;%H:%M:%S&#x27;, time.localtime())</span><br><span class="line">    print(time_now + &quot;: release the lock!&quot;)</span><br></pre></td></tr></table></figure>

<p>先后将<code>main1.py</code>和<code>main2.py</code>跑起来，输出如下： <img src="/../assets/2023/02/file_lock_result.jpg" alt="file_lock_result"></p>
<p>显然，<code>main1.py</code>先完成了对文件上锁，<code>main2.py</code>就一直处于等待中，一直到<code>main1.py</code>释放了锁，<code>main2.py</code>实现了文件上锁，从而实现了对文件的互斥性访问。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/02/19/python-file-lock/" data-id="clufcjlqf000b7o15gfw5ago4" data-title="python实现文件锁" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python-threads-processes" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/12/04/python-threads-processes/" class="article-date">
  <time class="dt-published" datetime="2022-12-04T13:43:42.000Z" itemprop="datePublished">2022-12-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/12/04/python-threads-processes/">python多进程与多线程</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>多进程和多线程在编程中是一个重要的特性，本文主要讲解在python中如何实现多线程和多进程。</p>
<h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p><strong>python中多线程速度慢，不建议使用！</strong></p>
<p>python中的多线程机制不够完善，用起来效果很鸡肋。以我的实现为例，在不使用多线程的情况下运行一次需要5s左右，使用多线程之后反而需要14s之久。这显然是不可接受的，所以不推荐在python中使用多线程，如果真的需要并发，建议使用多进程代替。</p>
<p>python中的多线程速度慢究其原因在于python中的<a target="_blank" rel="noopener" href="https://wiki.python.org/moin/GlobalInterpreterLock">Global Interpreter Lock</a>(GIL)，线程只有获得GIL才可运行，导致的结果是每次最多只有一个线程在运行。GIL导致运行慢的原因不在本文讨论范围，感兴趣可自行搜索。</p>
<p>不过python中的多进程基于多线程实现，两者的接口使用方式几乎是一样的，所以本文还是对多线程实现做出讲解。</p>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><p>python中多线程通过<code>threading</code>库实现，创建线程有两种方法，不过根本上都是需要用到<code>threading.Thread</code>类。</p>
<p><strong>方法1：自定义线程的运行内容</strong></p>
<p>这种方法需要自己提前以<strong>函数</strong>的形式定义好要在线程中运行的程序。为直观起见，这里我只使用了两个线程，两者均运行同一个程序函数<code>do_something</code>。此外，我这里将输出用日志打印，这样可以显示运行时间，便于理解线程的执行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="comment"># 日志配置</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO, <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s %(message)s&#x27;</span>, datefmt=<span class="string">&#x27;%H:%M:%S&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 要在线程中运行的程序</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_something</span>(<span class="params">name</span>):</span><br><span class="line">    logging.info(name + <span class="string">&#x27; is playing toy.&#x27;</span>)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    logging.info(name + <span class="string">&#x27; leaves.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    children = [<span class="string">&#x27;Tom&#x27;</span>, <span class="string">&#x27;John&#x27;</span>]</span><br><span class="line">    <span class="comment"># 创建线程</span></span><br><span class="line">    threads = [threading.Thread(target=do_something, args=(child,)) <span class="keyword">for</span> child <span class="keyword">in</span> children]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 开启进程</span></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.start()</span><br><span class="line">    <span class="comment"># 等待进程结束</span></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.join()</span><br></pre></td></tr></table></figure>

<p>运行上述代码，我得到的输出是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">18:50:31 Tom have access to toy: beer</span><br><span class="line">18:50:31 John have access to toy: beer</span><br><span class="line">18:50:32 Tom leaves!</span><br><span class="line">18:50:32 John leaves!</span><br></pre></td></tr></table></figure>

<p>可见，两个线程同时开始运行，并在执行结束后分别退出。</p>
<p><strong>方法2：自定义线程</strong></p>
<p>相比于方法1以函数的形式定义线程要运行的程序，方法2直接定义一个要运行的线程，该线程需继承<code>threading.Thread</code>类，并重写其<code>run</code>方法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="comment"># 日志配置</span></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO, <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s %(message)s&#x27;</span>, datefmt=<span class="string">&#x27;%H:%M:%S&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 线程类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DoSomething</span>(threading.Thread):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, name, *args, **kargs</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__(*args, **kargs)</span><br><span class="line">        self.name = name</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;运行程序写在这里&#x27;&#x27;&#x27;</span></span><br><span class="line">        logging.info(self.name + <span class="string">&#x27; is playing toy.&#x27;</span>)</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        logging.info(self.name + <span class="string">&#x27; leaves.&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    children = [<span class="string">&#x27;Tom&#x27;</span>, <span class="string">&#x27;John&#x27;</span>]</span><br><span class="line">    threads = [DoSomething(name=child) <span class="keyword">for</span> child <span class="keyword">in</span> children]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.join()</span><br></pre></td></tr></table></figure>

<p>运行该程序输出和方法1类似。</p>
<h3 id="共享资源"><a href="#共享资源" class="headerlink" title="共享资源"></a>共享资源</h3><p>在运行多线程的时候经常需要多个线程共享资源，要实现这一点只需对上边的程序稍微改进即可，这里以方法1为例说明，我额外创建了一个<code>Shared</code>类用于多线程共享。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line">logging.basicConfig(level=logging.INFO, <span class="built_in">format</span>=<span class="string">&#x27;%(asctime)s %(message)s&#x27;</span>, datefmt=<span class="string">&#x27;%H:%M:%S&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 共享类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Shared</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    toy = <span class="string">&#x27;beer&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">do_something</span>(<span class="params">resource, name</span>):</span><br><span class="line">    logging.info(name + <span class="string">&#x27; have access to toy: &#x27;</span> + resource.toy)</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    logging.info(name + <span class="string">&#x27; leaves!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 共享资源</span></span><br><span class="line">    resource = Shared()</span><br><span class="line"></span><br><span class="line">    children = [<span class="string">&#x27;Tom&#x27;</span>, <span class="string">&#x27;John&#x27;</span>]</span><br><span class="line">    threads = [threading.Thread(target=do_something, args=(resource, child)) <span class="keyword">for</span> child <span class="keyword">in</span> children]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> thread <span class="keyword">in</span> threads:</span><br><span class="line">        thread.join()</span><br></pre></td></tr></table></figure>

<p>使用方法2共享资源也是同理。</p>
<h2 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h2><p>相对于python中多线程存在的硬伤，多进程则靠谱很多。python任何希望用多线程实现的程序都可以用多进程代替，而且多进程提供了和多线程非常相似的API接口，迁移起来非常方便。</p>
<p>python中多进程通过<code>multiprocessing</code>库实现，实现的类是<code>multiprocessing.Process</code>。由于和多线程接口一致，多进程也有两种实现方式，而且多进程也可以像多线程一样共享资源。</p>
<p>以方法1为例，要想将多线程改写为多进程，只需要导入<code>multiprocessing</code>库并将<code>threading.Thread</code>替换为<code>multiprocessing.Process</code>即可。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line"># 导入多进程库</span><br><span class="line">import multiprocessing</span><br><span class="line"></span><br><span class="line">import logging</span><br><span class="line">logging.basicConfig(level=logging.INFO, format=&#x27;%(asctime)s %(message)s&#x27;, datefmt=&#x27;%H:%M:%S&#x27;)</span><br><span class="line"></span><br><span class="line">class Shared(object):</span><br><span class="line">    toy = &#x27;beer&#x27;</span><br><span class="line"></span><br><span class="line">def do_something(resource, name):</span><br><span class="line">    logging.info(name + &#x27; have access to toy: &#x27; + resource.toy)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    logging.info(name + &#x27; leaves!&#x27;)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    resource = Shared()</span><br><span class="line"></span><br><span class="line">    children = [&#x27;Tom&#x27;, &#x27;John&#x27;]</span><br><span class="line">    # 替换</span><br><span class="line">    threads = [multiprocessing.Process(target=do_something, args=(resource, child)) for child in children]</span><br><span class="line"></span><br><span class="line">    for thread in threads:</span><br><span class="line">        thread.start()</span><br><span class="line"></span><br><span class="line">    for thread in threads:</span><br><span class="line">        thread.join()</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/12/04/python-threads-processes/" data-id="clufcjlqk000q7o15h8y16xxz" data-title="python多进程与多线程" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-pytorch-upsample-convtranspose" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/12/04/pytorch-upsample-convtranspose/" class="article-date">
  <time class="dt-published" datetime="2022-12-04T08:18:36.000Z" itemprop="datePublished">2022-12-04</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/12/04/pytorch-upsample-convtranspose/">pyTorch中Upsample和ConvTranspose区分</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在pytorch中，<code>nn.Upsample</code>和<code>ConvTranspose</code>（包含<code>nn.ConvTranspose1d</code>、<code>nn.ConvTranspose2d</code>和<code>nn.ConvTranspose3d</code>）均可以实现上采样。那么是模型设计上应该使用哪一种呢？</p>
<p>实际上，在模型中应该使用哪一种并无严格的约束条件，习惯上可以视设计的网络层的作用而定。</p>
<p><code>nn.Upsample</code>仅通过插值实现，没有参数也不需要模型训练学习。如果只是想单纯实现特征图上采样或者比较在意模型参数量，那么<code>nn.Upsample</code>必然是很好的选择。</p>
<p><code>ConvTranspose</code>则是通过转置卷积实现，会引入一定的参数量，故需要进行训练，相对于<code>nn.Upsample</code>其能获得更加细粒度的高频信息。如果想让模型学会如何上采样那么就可以考虑<code>ConvTranspose</code>，如在GAN中生成图像。</p>
<p>当然，两者的适用场景不是绝对的。以UNet为例，在原文中上采样用转置卷积完成，而后续很多实现则是用Upsample+$1\times 1$conv实现，这样的一个明显好处是相对于转置卷积来说参数量更少，而在性能上两者几乎是没有区别的。（参考Github作者@jvanvugt的<a target="_blank" rel="noopener" href="https://github.com/jvanvugt/pytorch-unet/blob/master/README.md#discussion-of-parametersarchitecture">讨论</a>）。</p>
<p><strong>区别总结</strong>：</p>
<table>
<thead>
<tr>
<th></th>
<th>Upsample</th>
<th>ConvTranspose</th>
</tr>
</thead>
<tbody><tr>
<td>实现机制</td>
<td>插值</td>
<td>转置卷积，可训练学习</td>
</tr>
<tr>
<td>参数</td>
<td>无</td>
<td>有</td>
</tr>
<tr>
<td>可处理数据维度</td>
<td>1D、2D、3D</td>
<td>ConvTranspose1d：1D ConvTranspose2d：2D ConvTranspose3d：3D</td>
</tr>
<tr>
<td>场景</td>
<td>分割、检测等特征上采样</td>
<td>GAN、高分辨率</td>
</tr>
</tbody></table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/12/04/pytorch-upsample-convtranspose/" data-id="clufcjlqq001l7o152d60amef" data-title="pyTorch中Upsample和ConvTranspose区分" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pyTorch/" rel="tag">pyTorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-norm-layers" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/10/30/norm-layers/" class="article-date">
  <time class="dt-published" datetime="2022-10-30T10:12:32.000Z" itemprop="datePublished">2022-10-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/">模型结构设计</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/10/30/norm-layers/">归一化层及在模型中的使用</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在卷积神经网络CNN中，如BN、GN等归一化层得到了普遍使用。这些层之间有什么区别、分别在什么情况下使用我一直是模棱两可，现在特意整理记录一下，搞清楚这些层的原理和区别对设计模型网络也大有裨益。</p>
<p>此外，本文将特意花一些篇幅探讨对各种归一化方法来说，其前边的<strong>卷积层是否需要bias</strong>，这部分内容在本文<a href="##%E4%BB%8E%E5%8D%B7%E7%A7%AF%E8%AF%B4%E8%B5%B7%E2%80%94%E2%80%94%E6%98%AF%E5%90%A6%E9%9C%80%E8%A6%81bias%EF%BC%9F">第二部分</a>。</p>
<h2 id="归一化层区分"><a href="#归一化层区分" class="headerlink" title="归一化层区分"></a>归一化层区分</h2><p>归一化用于解决深度学习中的内部协变量移位（internal covariate shift）现象，可以用于缓解梯度爆炸、提高模型收敛速度，同时能起到正则化的作用，防止过拟合。</p>
<p>目前的主流归一化层有Batch Norm(BN)、Layer Norm(LN)、Instance Norm(IN)、Group Norm(GN)。其区别可以参考下图，这张图来自于论文<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.08494.pdf">Group Normalization</a>[1]。</p>
<p><img src="/..%5Cassets%5C2022%5C10/x2.png" alt="norms"></p>
<p>归纳起来说，无论是哪一种归一化，本质上都是将特征图分为若干个部分，分别对每个部分做归一化使其数值范围符合特定的正态分布，所以对第<code>i</code>个部分的归一化均可以用下式表示：<br>$$<br>\hat{x}_i&#x3D;\frac{1}{\sigma_i}(x_i-\mu_i)<br>$$<br>不同归一化的区别仅在于如何划分特征图。</p>
<p>定义有一个特征图$\mathbf{x} \in \mathbb{R}^{N\times C \times H \times W}$，我们要对这个特征图做不同的归一化。</p>
<p>**Batch Norm(BN)**[2]</p>
<p>BN的应用应该说是最广的，但是其对batchsize的大小很敏感，只建议在batchsize不低于8的时候使用。</p>
<p>BN逐通道地对整个batch的特征图做归一化，也就是说每次做归一化的特征图维度为$N\times H\times W$。下边通过代码表示一下计算均值和方差的过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># BN</span></span><br><span class="line">mean = x.mean(dim=(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>)) <span class="comment"># shape: [C,]</span></span><br><span class="line">std  = x.std(dim=(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>))  <span class="comment"># shape: [C,]</span></span><br></pre></td></tr></table></figure>

<p>**Layer Norm(LN)**[3]</p>
<p>LN多用于RNN，在卷积神经网络上很少使用。</p>
<p>与BN相反，LN逐输入地对所有通道的特征图做归一化，每次归一化的特征图维度为$C\times H\times W$，代码表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># LN</span><br><span class="line">mean = x.mean(dim=(1,2,3)) # shape: [N,]</span><br><span class="line">std  = x.std(dim=(1,2,3))  # shape: [N,]</span><br></pre></td></tr></table></figure>

<p>**Instance Norm(IN)**[4]</p>
<p>IN主要用于生成式模型，如基于GAN的图像生成、图像风格迁移等。</p>
<p>IN可以看作是BN或者LN的特例（$N&#x3D;1$时的BN或者$C&#x3D;1$时的LN），其只对单个特征图做归一化，单特征图维度为$H\times W$，代码表示为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># IN</span><br><span class="line">mean = x.mean(dim=(2,3)) # shape: [N. C]</span><br><span class="line">std  = x.std(dim=(2,3))  # shape: [N, C]</span><br></pre></td></tr></table></figure>

<p><strong>Group Norm(GN)</strong></p>
<p>由于GN的性能不受batchsize影响，在batchsize比较小的时候，可以用GN代码BN。</p>
<p>GN将特征图沿通道均分为$G$组，分别为每一组做归一化，每次归一化的特征图维度为$(\frac CG)\times H\times W$，代码表示为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GN</span></span><br><span class="line">x_groups = x.chunk(G, dim=<span class="number">1</span>)</span><br><span class="line">x = torch.cat(x_groups, dim=<span class="number">0</span>) <span class="comment"># shape: [N*G, C//G, H, W]</span></span><br><span class="line">mean = x.mean(dim=(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>)) <span class="comment"># shape: [N*G,]</span></span><br><span class="line">mean = mean.view(N, G)     <span class="comment"># shape: [N, G]</span></span><br><span class="line">std = x.std(dim=(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))  <span class="comment"># shape: [N*G,]</span></span><br><span class="line">std  = std.view(N, G)      <span class="comment"># shape: [N, G]</span></span><br></pre></td></tr></table></figure>

<h2 id="从卷积说起——是否需要bias？"><a href="#从卷积说起——是否需要bias？" class="headerlink" title="从卷积说起——是否需要bias？"></a>从卷积说起——是否需要bias？</h2><p>我们在设计模型结构的时候应该经常看到类似下边的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BaseConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels</span>) -&gt; <span class="literal">None</span>:</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure>

<p><code>nn.Conv2d</code>中其他参数都很熟悉，<code>bias=False</code>是为什么呢？</p>
<p>本节将探讨这一问题，解决什么归一化不需要bias、为什么不需要的问题。</p>
<p><strong>卷积实现</strong></p>
<p>在pytorch中，卷积通过类 <code>nn.Conv2d()</code>实现，卷积层的参数有权重（weight）$\mathbf{w}$和偏置（bias）$\mathbf{b}$。</p>
<p>定义一个卷积层，其输入通道数为$C_{in}$，输出通道数为$C _{out}$，卷积核尺寸为$k$：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv = nn.Conv2d(C_in, C_out, kernel_size=k, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>那么有$\mathbf{w} \in \mathbb{R}^{C_{out}\times C_{in}\times k \times k}$，$\mathbf{b} \in \mathbb{R}^{C_{out}}$。</p>
<p>也就是说，对于每个输出层来说，都有一个维度为$C_{in}\times k \times k$的卷积核在输入特征图上滑动计算，计算的结果再与一个偏置值相加得到。所以说$\mathbf{b}$直接作用在通道方向上，<strong>逐通道</strong>地加。</p>
<p>逐通道是不是很熟悉？没错，BN也是逐通道的，那么在使用BN的情况下，即使加了bias最后也会在减去均值的时候被去掉，因此，这时候添加bias将不会产生任何作用，反而白白占用显存和运算量。</p>
<p><strong>数学推理证明</strong></p>
<p>我们可以以BN为例推导一下这个过程。为简化过程，只考虑输出特征图的一个通道特征图$\mathbf{y}c \in \mathbb{R}^{N\times H\times W}, \forall c\in {1,2…C}$。那么$\mathbf{y}c$可以如下计算：<br>$$<br>\mathbf{y}c &#x3D; \mathbf{w}c\mathbf{x} + b,\ \forall \mathbf{w}c \in \mathbb{R}^{C{in}\times k \times k}<br>$$<br>归一化的首先将特征转换为标准正态分布，这个过程计算为：<br>$$<br>\mathbf{\hat y}c&#x3D;\frac {\mathbf{y}c-mean(\mathbf{y}c)}{std(\mathbf{y}c)} \ &#x3D;\frac {\mathbf{w}c\mathbf{x}+b - (mean(\mathbf{w}c\mathbf{x})+b)}{std(\mathbf{w}c\mathbf{x})} \ &#x3D; \frac{\mathbf{w}c\mathbf{x}-mean(\mathbf{w}c\mathbf{x})}{std(\mathbf{w}c\mathbf{x})}<br>$$<br> 从过程中可以很明显看到，偏差$b$在计算过程中被完全消去了。</p>
<p>实际上，如果我们分别对LN、IN和GN都按上式计算的话就会发现，bias对于IN来说也是没有意义的，但是对于LN和GN则有意义。</p>
<p><strong>结论</strong></p>
<p>当归一化在与通道垂直的方向上做（逐通道）时，就不应该添加bias。如果模型中使用BN和IN，那么都不应该加bias，而GN和LN则应该加bias。</p>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><p>[1]. <em>Yuxin Wu and Kaiming He. Group Normalization. In ECCV, 2018.</em></p>
<p>[2]. <em>Sergey Ioffe and Christian Szegedy. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In ICML, 2015.</em></p>
<p>[3]. <em>Lei Jimmy Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization. arXiv:1607.06450, 2016.</em></p>
<p>[4]. <em>Dmitry Ulyanov, Andrea Vedaldi and Victor S. Lempitsky. Instance normalization: The missing ingredient for fast stylization. arXiv:1607.08022, 2016.</em></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/10/30/norm-layers/" data-id="clufcjlqi000g7o15f9769oiv" data-title="归一化层及在模型中的使用" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-linux-user-python-config" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/10/23/linux-user-python-config/" class="article-date">
  <time class="dt-published" datetime="2022-10-23T08:24:55.000Z" itemprop="datePublished">2022-10-23</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/10/23/linux-user-python-config/">linux中非root权限用户python配置详解</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>在使用Linux的过程中，经常需要用到系统默认版本之外的python版本，甚至是需要自行安装符合需求的版本。对于没有root权限的用户来说，配置起来似乎非常困难，实际上这一切确实是不需要root权限就可以完成的。</p>
<p>值得补充的是，本文介绍的方法不局限于python，对于用户自己安装的软件、包等也是一样的步骤，掌握了原理，方法便可以一通百通。</p>
<h2 id="local作用"><a href="#local作用" class="headerlink" title=".local作用"></a>.local作用</h2><p>这部分主要介绍<code>.local</code>文件夹，若对此不感兴趣可以跳过，不会影响后续环境配置。</p>
<p>提到为单个用户配置特定单用的数据就不能不说<code>.local</code>文件夹，这是一个路径固定为<code>/home/[username]/.local</code>的文件夹，用于存储专用于用户（user-specific）的程序数据，比如安装的用户程序、python模块等。同时由于<code>.local</code>处于用户的根目录下，对其操作不需要root权限。</p>
<p>所以，在单个用户配置python、pip等环境时，理论上都应该和<code>.local</code>文件夹打交道（实际上，不使用<code>.local</code>也是可以的，但是从规范的角度看，<code>.local</code>无疑是最推荐的）。</p>
<h2 id="链接到自己所需的版本"><a href="#链接到自己所需的版本" class="headerlink" title="链接到自己所需的版本"></a>链接到自己所需的版本</h2><p>这里介绍最常遇到的情况，即系统中存在多个版本的python，而默认的python又不是自己想要的。举例来讲，比如系统中同时安装有python2.7和python3.8，默认python是2.7，想要将python3.8作为默认python就需要我们自己做链接了。</p>
<p>先说一下原理：先创建一个软链接<code>.local/bin/python</code>指向python3.8，然后将<code>.local/bin</code>添加到环境变量<code>PATH</code>最前边。</p>
<p>这样系统将优先从<code>.local/bin</code>中找python，从而可以顺理成章得根据软链接找到python3.8了。</p>
<p><strong>step1：</strong>找到python3.8及其pip的安装路径。</p>
<p>注意配置的时候建议一并配置pip，否则可能会出现python和pip版本不一致的情况。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">which python3.8</span><br><span class="line">which pip3.8</span><br></pre></td></tr></table></figure>

<p>一般来讲，系统中python的安装路径都在<code>/usr/bin</code>下，这里就以<code>/usr/bin/python3.8</code>和<code>/usr/bin/pip3.8</code>为例继续。</p>
<p><strong>step2：</strong>创建软链接：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将原本的链接删除，若原本没有可跳过</span></span><br><span class="line"><span class="built_in">rm</span> ~/.local/bin/python ~/.local/bin/pip</span><br><span class="line"><span class="comment"># 创建软链接，指向自己想要的版本</span></span><br><span class="line"><span class="built_in">ln</span> -s /usr/bin/python3.8 ~/.local/bin/python</span><br><span class="line"><span class="built_in">ln</span> -s /usr/bin/pip3.8 ~/.local/bin/pip</span><br></pre></td></tr></table></figure>

<p><strong>step3：</strong>将<code>.local/bin</code>添加到环境变量<code>PATH</code>中（_若已添加，可跳过_）：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 打开~/.bashrc文件，进入编辑模式</span></span><br><span class="line">vim ~/.bashrc</span><br><span class="line"><span class="comment"># 添加环境变量</span></span><br><span class="line"><span class="built_in">export</span> PATH=~/.local/bin/:<span class="variable">$PATH</span></span><br><span class="line"><span class="comment"># 退出后 source一下使其生效</span></span><br><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>这样，新的python就配置好了，可以在命令行输入一下<code>python</code>试试~</p>
<h2 id="安装自己所需的版本"><a href="#安装自己所需的版本" class="headerlink" title="安装自己所需的版本"></a>安装自己所需的版本</h2><p>这里介绍相对不常遇到的情况，即系统中没有安装自己想要的python。比如系统中安装了python2.7和python3.8，而自己需要python3.6，那就需要用户自己安装一个了。</p>
<p>同样也是先说原理：在用户目录下安装python，之后和上一节一样将其链接到<code>.local/bin/python</code>中即可。</p>
<p><strong>step1</strong>：下载和准备工作。</p>
<p>从<a target="_blank" rel="noopener" href="https://www.python.org/ftp/python/">python官网</a>下载自己需要的python版本，这里即以安装python3.6.9为例，其他版本也是一样的操作。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget https://www.python.org/ftp/python/3.6.9/Python-3.6.9.tgz</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar zxfv Python-3.6.9.tgz</span><br><span class="line"><span class="comment"># 添加权限，否则无法执行安装</span></span><br><span class="line">find Python-3.6.9/Python -<span class="built_in">type</span> d  xargs <span class="built_in">chmod</span> 0755</span><br><span class="line"><span class="comment"># 进入解压后的目录</span></span><br><span class="line"><span class="built_in">cd</span> Python-3.6.9</span><br></pre></td></tr></table></figure>

<p><strong>step2：</strong>执行安装。</p>
<p>注意这里<code>--prefix</code>后的路径就是python的安装路径，此路径必须是绝对路径，默认我们将其安装在<code>.local</code>。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/home/[username]/.local</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"><span class="comment"># 退出路径</span></span><br><span class="line"><span class="built_in">cd</span></span><br></pre></td></tr></table></figure>

<p>至此，python3.6就安装完成了，后边的步骤其实和上一节的步骤是一样的。</p>
<p><strong>step3：</strong>设置python和pip软链接。</p>
<p>若<code>.local/bin</code>中原本没有<code>python</code>和<code>pip</code>，这一步可跳过，因为在安装的时候这些软链接就已经自动配置好了。否则就需要手动设置，步骤和上一节step2是相同的。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> .<span class="built_in">local</span>/bin</span><br><span class="line"><span class="comment"># 可以先ls 看一下有没有名为python和pip的文件，没有的话可以跳过step3</span></span><br><span class="line"><span class="built_in">rm</span> python pip</span><br><span class="line"><span class="comment"># 设置软链接，注意安装的python3.6其实也在这一级目录里</span></span><br><span class="line"><span class="built_in">ln</span> -s python3.6 python</span><br><span class="line"><span class="built_in">ln</span> -s pip3.6 pip</span><br></pre></td></tr></table></figure>

<p><strong>step4：</strong>将<code>.local/bin</code>添加到环境变量<code>PATH</code>中，和上一节step3是一样的。</p>
<p>同样若<code>.local/bin</code>已被添加到环境变量中的话可跳过。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.bashrc</span><br><span class="line">export PATH=~/.local/bin/:$PATH</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure>

<p>这样，就可以开心地使用自己安装的版本了。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/10/23/linux-user-python-config/" data-id="clufcjlqf000a7o15630o31mi" data-title="linux中非root权限用户python配置详解" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/python/" rel="tag">python</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-resnet-residual-block" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/10/16/resnet-residual-block/" class="article-date">
  <time class="dt-published" datetime="2022-10-16T12:44:33.000Z" itemprop="datePublished">2022-10-16</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/10/16/resnet-residual-block/">ResNet残差块详解</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>论文链接：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.03385.pdf">Deep Residual Learning for Image Recognition</a></p>
<p>ResNet在深度学习领域可以说是一个人尽皆知的模型，在各种模型的backbone上得到了广泛的应用。其理论简洁、结构简单，因此往往会让人忽视其巧妙的设计。我在最近设计模型结构时逐渐发现这一点，故写此文总结一下。</p>
<h2 id="再看一遍残差块"><a href="#再看一遍残差块" class="headerlink" title="再看一遍残差块"></a>再看一遍残差块</h2><p>这里简单回顾一下残差块和跳跃链接，如果足够熟悉的话可以跳过。</p>
<p>在ResNet出现之前，人们发现随着神经网络层数的增加，梯度消失现象越来越严重，模型的性能经常不再增加甚至还有所下降，这使得模型的深度受到限制。</p>
<p>ResNet使用残差模块引入跳跃连接(skip connection)结构解决了这一问题。然而这不是什么复杂的运算，其公式简单地令人咂舌：<br>$$<br>\mathcal{H}(\mathbf{x}):&#x3D;\mathcal{F}(\mathbf{x})+\mathbf{x}<br>$$<br> 这里$\mathbf{x}$表示一个残差块的输入特征图，$\mathcal{F}(\mathbf{x})$表示$\mathbf{x}$经过若干卷积块后的结果。</p>
<p>以前的模型直接将$\mathcal{F}(\mathbf{x})$作为最终输出结果，而ResNet创造性的将其与$\mathbf{x}$相加的结果作为最终结果。对应的意义是<strong>最终想要的知识是$\mathcal{H}(\mathbf{x})$，已经学到了知识$\mathbf{x}$，那么残差块里边的网络只需要学习到知识$\mathcal{H}(\mathbf{x})-\mathbf{x}$即可</strong>。</p>
<p><img src="/..%5Cassets%5C2022%5C10%5Cresnet-1.png" alt="Residual learning: a building block."></p>
<p>图1：一个ResNet残差块结构图</p>
<h2 id="残差块结构"><a href="#残差块结构" class="headerlink" title="残差块结构"></a>残差块结构</h2><p>很多人（其实是我）可能没有注意到的一点是ResNet提供了两种残差块。第一种被称为<code>building block</code>，主要用于浅层网络，第二种被称为<code>bottleneck</code>，主要用于深层网络。两者结构如图2所示。</p>
<p><img src="/../assets%5C2022%5C10%5Cresnet-2.png" alt="A deeper residual function "></p>
<p>图2：左图为building block，右图为bottleneck</p>
<p>值得注意的是，上一部分的公式只是一个简化模型，并不严格与实现一致。实际上，残差块的最后一层的激活函数是在与$\mathbf{x}$相加后才使用的。</p>
<p>代码实现图2中的卷积块：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ConvBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, out_channels, k_size=<span class="number">3</span>, activation=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        k_size:     kernel size, by default is 3</span></span><br><span class="line"><span class="string">        activation: whether use activation</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.blocks = [</span><br><span class="line">            nn.Conv2d(in_channels, out_channels, kernel=k_size, stride=<span class="number">1</span>, padding=(k_size-<span class="number">1</span>)//<span class="number">2</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channels)</span><br><span class="line">            ]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> activation:</span><br><span class="line">            self.blocks.append(</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Sequential(*self.blocks)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure>

<h3 id="building-block"><a href="#building-block" class="headerlink" title="building block"></a>building block</h3><p>building block只堆叠了两个相同的$3\times3$卷积块，这样简单的结构适用于通道比较窄的情况。所以其主要用于浅层网络，如ResNet18和ResNet34。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">BuildingBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, channels</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.block = nn.Sequential(</span><br><span class="line">            ConvBlock(channels, channels),</span><br><span class="line">            ConvBlock(channels, channels, activation=<span class="literal">False</span>)</span><br><span class="line">        )</span><br><span class="line">        self.act = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.act(x + self.block(x))</span><br></pre></td></tr></table></figure>

<h3 id="bottleneck"><a href="#bottleneck" class="headerlink" title="bottleneck"></a>bottleneck</h3><p>相比于building block的简单结构，bottleneck设计则非常巧妙。在通道非常宽的情况下（如1024）直接堆叠$3\times3$卷积块将会使参数量非常巨大。</p>
<p>因此bottleneck堆叠了三个卷积块，其中第一个卷积块用于降低通道数量，第三个卷积块用于复原通道数量。第一个和第三个卷积块涉及到的通道比较宽因此使用$1\times1$卷积，第二个卷积块涉及到的通道比较窄因此使用$3\times3$卷积。</p>
<p>代码实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">class Bottleneck(nn.Module):</span><br><span class="line">    def __init__(self, in_channels, mid_channels):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.block = nn.Sequential(</span><br><span class="line">            ConvBlock(in_channels,  mid_channels, k_size=1),</span><br><span class="line">            ConvBlock(mid_channels, mid_channels, k_size=3),</span><br><span class="line">            ConvBlock(mid_channels, in_channels,  k_size=1, activation=False),</span><br><span class="line">        )</span><br><span class="line">        self.act = nn.ReLU(inplace=True)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        return self.act(x + self.block(x))</span><br></pre></td></tr></table></figure>

<h2 id="一些思考"><a href="#一些思考" class="headerlink" title="一些思考"></a>一些思考</h2><p>ResNet的残差块设计个人觉得真是非常巧妙，所谓大道至简，最有效的东西未必总是要很复杂。</p>
<p>此外，bottleneck的设计也非常精彩，其可以在不影响性能的情况下有效减少参数量。在实际模型设计的时候我们经常要考虑参数量、运算量等，bottleneck的结构可以作为一个不错的参考。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/10/16/resnet-residual-block/" data-id="clufcjlqq001m7o15a8aq62uo" data-title="ResNet残差块详解" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1/">模型结构设计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/">深度学习模型部署</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">编程语言</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/pyTorch/" rel="tag">pyTorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python/" rel="tag">python</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/" rel="tag">数据集</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E8%AE%BA%E6%96%87/" rel="tag">论文</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/pyTorch/" style="font-size: 10px;">pyTorch</a> <a href="/tags/python/" style="font-size: 20px;">python</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/" style="font-size: 15px;">数据集</a> <a href="/tags/%E8%AE%BA%E6%96%87/" style="font-size: 10px;">论文</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/03/">March 2024</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/03/30/Config-GitHub-Pages-with-Hexo/">使用Hexo搭建GitHub博客</a>
          </li>
        
          <li>
            <a href="/2024/03/30/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2023/03/05/pytorch-model-to-onnx/">pyTorch模型转onnx</a>
          </li>
        
          <li>
            <a href="/2023/03/04/pytorch-model-to-torchscript/">pyTorch模型转torchscript</a>
          </li>
        
          <li>
            <a href="/2023/02/19/python-file-lock/">python实现文件锁</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2024 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>